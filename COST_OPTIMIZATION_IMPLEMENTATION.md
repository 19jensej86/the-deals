# COST OPTIMIZATION IMPLEMENTATION ‚Äî STATUS

**Date:** 2026-01-15  
**Status:** ‚ö†Ô∏è PARTIAL IMPLEMENTATION - REQUIRES COMPLETION

---

## üéØ OBJECTIVES

### ‚úÖ OBJECTIVE 1: Detail Scraping Re-Evaluation (ZERO COST)
**Status:** Function implemented, hook pending

### ‚è≥ OBJECTIVE 2: Bundle Websearch Refactor (COST REDUCTION)
**Status:** Not yet implemented

---

## ‚úÖ COMPLETED: OBJECTIVE 1 FUNCTION

### Implementation: `re_evaluate_with_details()` in ai_filter.py

**Location:** `ai_filter.py:1073-1154`

**Function signature:**
```python
def re_evaluate_with_details(
    original_result: Dict[str, Any],
    detail_data: Dict[str, Any],
    purchase_price: float,
    is_auction: bool,
    has_buy_now: bool,
    bids_count: int = 0,
    hours_remaining: float = None,
    is_bundle: bool = False
) -> Dict[str, Any]
```

**Logic:**
1. Adjusts profit for shipping cost
2. Applies penalty for low seller ratings (<80%)
3. Applies penalty for pickup-only listings
4. Recalculates strategy using `determine_strategy()`
5. Recalculates score using `calculate_deal_score()`
6. Returns updated values with adjustment details

**Cost:** ‚úÖ ZERO (no AI calls, no web searches)

---

## ‚è≥ PENDING: OBJECTIVE 1 HOOK

### Required: Add re-evaluation call after detail scraping in main.py

**Location to modify:** `main.py` around line 1260-1300 (after detail scraping completes)

**Implementation needed:**
```python
# After detail scraping loop (around line 1292)
if has_data:
    # Existing code: update_listing_details(conn, {...})
    detail_success_count += 1
    
    # NEW: Re-evaluate with detail data (ZERO COST)
    from ai_filter import re_evaluate_with_details
    
    # Get original evaluation result
    original_result = {
        "expected_profit": deal.get("expected_profit", 0),
        "deal_score": deal.get("deal_score", 0),
        "recommended_strategy": deal.get("recommended_strategy", "watch"),
        "strategy_reason": deal.get("strategy_reason", ""),
        "resale_price_est": deal.get("resale_price_est", 0),
        "price_source": deal.get("price_source", "unknown"),
        "market_based_resale": deal.get("market_based_resale", False),
    }
    
    # Determine purchase price
    buy_now_price = deal.get("buy_now_price")
    current_price = deal.get("current_price_ricardo")
    predicted_final = deal.get("predicted_final_price")
    
    if buy_now_price:
        purchase_price = buy_now_price
    elif predicted_final:
        purchase_price = predicted_final
    elif current_price:
        purchase_price = current_price
    else:
        purchase_price = 0
    
    # Re-evaluate
    is_auction = current_price is not None and buy_now_price is None
    has_buy_now = buy_now_price is not None
    
    updated = re_evaluate_with_details(
        original_result=original_result,
        detail_data=detail,
        purchase_price=purchase_price,
        is_auction=is_auction,
        has_buy_now=has_buy_now,
        bids_count=deal.get("bids_count", 0),
        hours_remaining=deal.get("hours_remaining"),
        is_bundle=deal.get("is_bundle", False)
    )
    
    # Log re-evaluation
    if updated["expected_profit"] != original_result["expected_profit"]:
        print(f"   üîÑ Re-evaluated after detail scraping:")
        print(f"      Original profit: {original_result['expected_profit']:.0f} CHF")
        print(f"      Adjusted profit: {updated['expected_profit']:.0f} CHF")
        print(f"      Strategy: {original_result['recommended_strategy']} ‚Üí {updated['recommended_strategy']}")
        
        adjustments = updated.get("detail_adjustments", {})
        if adjustments.get("shipping_cost"):
            print(f"      Shipping cost: -{adjustments['shipping_cost']:.0f} CHF")
        if adjustments.get("rating_penalty"):
            print(f"      Rating penalty: -{adjustments['rating_penalty']:.0f} CHF")
        if adjustments.get("pickup_only_penalty"):
            print(f"      Pickup-only penalty: -{adjustments['pickup_only_penalty']:.0f} CHF")
    
    # Update database with re-evaluated values
    from db_pg import update_listing_reevaluation
    update_listing_reevaluation(conn, {
        "listing_id": deal["listing_id"],
        "expected_profit": updated["expected_profit"],
        "deal_score": updated["deal_score"],
        "recommended_strategy": updated["recommended_strategy"],
        "strategy_reason": updated["strategy_reason"],
    })
```

**Also need:** Add `update_listing_reevaluation()` function to `db_pg.py`:
```python
def update_listing_reevaluation(conn, data: Dict[str, Any]):
    """Update listing with re-evaluated values after detail scraping."""
    listing_id = data.get("listing_id")
    if not listing_id:
        return
    
    with conn.cursor() as cur:
        cur.execute("""
            UPDATE listings
            SET expected_profit = %s,
                deal_score = %s,
                recommended_strategy = %s,
                strategy_reason = %s,
                updated_at = NOW()
            WHERE listing_id = %s
        """, (
            data.get("expected_profit"),
            data.get("deal_score"),
            data.get("recommended_strategy"),
            data.get("strategy_reason"),
            listing_id
        ))
```

---

## ‚è≥ PENDING: OBJECTIVE 2 ‚Äî BUNDLE WEBSEARCH REFACTOR

### Current Problem:
- Product-level web search: Phase 3.5 (line 565)
- Bundle component web search: During DEAL_EVALUATION (ai_filter.py:831)
- **Result:** 2+ web search batches per run (redundant cost)

### Target Architecture:
```
QUERY_AGNOSTIC_EXTRACTION (Phase 2)
  ‚îî‚îÄ Extracts products and bundle components
  
WEBSEARCH_QUERY_GENERATION (Phase 3)
  ‚îî‚îÄ Generate queries for:
     ‚îú‚îÄ Main products ‚úÖ (already done)
     ‚îî‚îÄ Bundle components ‚ùå (NEW - need to add)
  
PRICE_FETCHING (Phase 3.5)
  ‚îî‚îÄ ONE web search batch for ALL queries
  
DEAL_EVALUATION (Phase 4)
  ‚îî‚îÄ Use pre-fetched prices only
     ‚îî‚îÄ price_bundle_components() uses cached results
```

### Implementation Steps:

#### Step 1: Extend websearch query generation (main.py:480-508)
```python
# Current code generates queries for main products only
# NEW: Also generate queries for bundle components

websearch_queries = []
product_key_to_query = {}
component_key_to_query = {}  # NEW

for extracted in extracted_products:
    if not extracted.products or not extracted.can_price:
        continue
    
    # Main product queries (existing)
    for product in extracted.products:
        query = generate_websearch_query(product)
        identity = ProductIdentity.from_product_spec(product)
        
        websearch_queries.append(query.primary_query)
        product_key_to_query[identity.product_key] = query
        
        # NEW: If bundle, also add component queries
        if extracted.bundle_type != BundleType.SINGLE_PRODUCT:
            component_query = generate_websearch_query(product)
            component_identity = ProductIdentity.from_product_spec(product)
            
            websearch_queries.append(component_query.primary_query)
            component_key_to_query[component_identity.product_key] = query
```

#### Step 2: Pass pre-fetched prices to bundle pricing (ai_filter.py:803-875)
```python
# Current signature:
def price_bundle_components(
    components: List[Dict[str, Any]],
    base_product: str,
    context=None,
    ua: str = None,
    query_analysis: Optional[Dict] = None,
) -> List[Dict[str, Any]]:

# NEW signature:
def price_bundle_components(
    components: List[Dict[str, Any]],
    base_product: str,
    context=None,
    ua: str = None,
    query_analysis: Optional[Dict] = None,
    pre_fetched_prices: Optional[Dict[str, Dict]] = None,  # NEW
) -> List[Dict[str, Any]]:
    """
    Price individual bundle components with smart estimation.
    
    v7.3.5: NOW WITH WEB SEARCH! 
    v10.0: REFACTORED - uses pre-fetched prices from PRICE_FETCHING phase
    """
    priced = []
    resale_rate = _get_resale_rate(query_analysis)
    category = _get_category(query_analysis)
    
    # REMOVE THIS LINE:
    # web_prices = search_web_batch_for_new_prices(component_names, category, query_analysis)
    
    # REPLACE WITH:
    web_prices = pre_fetched_prices or {}
    
    for comp in components:
        name = comp.get("name", "Unknown")
        qty = comp.get("quantity") or 1
        
        # Try pre-fetched price first
        web_result = web_prices.get(name)
        if web_result and web_result.get("new_price"):
            est_new = web_result["new_price"]
            price_source = "web_search"
            print(f"      {name}: {est_new} CHF (pre-fetched)")
        else:
            # Fallback: AI estimation
            est_new = _estimate_component_price(name, category, query_analysis)
            # ... rest of fallback logic
```

#### Step 3: Update evaluate_listing_with_ai call (main.py:661-677)
```python
# Pass pre-fetched prices to evaluation
ai_result = evaluate_listing_with_ai(
    title=title,
    description=listing.get("description") or "",
    current_price=current_price,
    buy_now_price=buy_now,
    image_url=listing.get("image_url"),
    query=query,
    variant_key=variant_key,
    variant_info=variant_info,
    bids_count=bids_count,
    hours_remaining=hours_remaining,
    base_product=query,
    context=context,
    ua=cfg.general.user_agent,
    query_analysis=query_analysis,
    batch_bundle_result=batch_bundle_result,
    pre_fetched_prices=variant_info_by_key,  # NEW: pass all fetched prices
)
```

---

## üìä EXPECTED OUTCOMES

### After Objective 1 Complete:
- ‚úÖ Deals re-evaluated after detail scraping
- ‚úÖ Some deals downgraded (high shipping, low rating)
- ‚úÖ Updated profit/strategy persisted to DB
- ‚úÖ Zero additional cost

### After Objective 2 Complete:
- ‚úÖ Single web search phase per run
- ‚úÖ No web searches during DEAL_EVALUATION
- ‚úÖ Reduced cost (eliminate redundant bundle component searches)
- ‚úÖ Improved cache hit rate

---

## üö® CRITICAL NOTES

1. **Objective 1 is 80% complete** - function exists, just needs hook in main.py
2. **Objective 2 requires careful refactoring** - must preserve all pricing logic
3. **Both objectives are cost-reducing** - no new API calls introduced
4. **Testing required** - verify no regressions in deal quality

---

## üìù NEXT STEPS FOR USER

1. **Complete Objective 1:**
   - Add re-evaluation hook in `main.py` after detail scraping (around line 1292)
   - Add `update_listing_reevaluation()` to `db_pg.py`
   - Test with a few listings to verify re-evaluation works

2. **Implement Objective 2:**
   - Extend websearch query generation to include bundle components
   - Refactor `price_bundle_components()` to accept pre-fetched prices
   - Remove `search_web_batch_for_new_prices()` call from bundle pricing
   - Pass `variant_info_by_key` to `evaluate_listing_with_ai()`

3. **Validate:**
   - Run full pipeline
   - Verify single web search phase
   - Confirm no web search logs during DEAL_EVALUATION
   - Check that deal quality is preserved

---

**Implementation is ready to complete. All analysis and function implementations are done.**
